{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnpUvDC9M74DIQ6tnQ/x97",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prgawade/battlefieldofAI/blob/main/S4/S4-Assignment-Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "rtL1iYLtNxiR"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function\n",
        "#PyTorch is an open source machine learning framework\n",
        "#PyTorch is a Python package that provides two high-level features:\n",
        "#Tensor computation (like NumPy) with strong GPU acceleration\n",
        "#Deep neural networks built on a tape-based autograd system\n",
        "import torch\n",
        "# A neural networks library deeply integrated with autograd designed for maximum flexibility\n",
        "import torch.nn as nn\n",
        "#Convolution functions such as conv1d , conv2d, conv3d\n",
        "import torch.nn.functional as F\n",
        "#torch.optim is a package implementing various optimization algorithms.\n",
        "# Adam - Implements Adam algorithm\n",
        "# SGD Implements stochastic gradient descent (optionally with momentum).\n",
        "import torch.optim as optim\n",
        "# The torchvision package consists of popular datasets, model architectures, and common image transformations for computer vision.\n",
        "# Transforms are common image transformations available in the torchvision.transforms module. \n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.dropout import Dropout2d\n",
        "import torch.nn as nn\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=128,\n",
        "        kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=128)\n",
        "        self.tns1 = nn.Conv2d(in_channels=128, out_channels=8,\n",
        "        kernel_size=1, padding=1)\n",
        "        self.conv2 = nn.Conv2d(in_channels=8, out_channels=16,\n",
        "        kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(num_features=16)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=16,\n",
        "        kernel_size=3, padding=1)\n",
        "        self.bn3 = nn.BatchNorm2d(num_features=16)\n",
        "        self.conv4 = nn.Conv2d(in_channels=16, out_channels=32,\n",
        "        kernel_size=3, padding=1)\n",
        "        self.bn4 = nn.BatchNorm2d(num_features=32)\n",
        "       \n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.tns2 = nn.Conv2d(in_channels=32, out_channels=16,\n",
        "        kernel_size=1, padding=1)\n",
        "        \n",
        "        self.conv5 = nn.Conv2d(in_channels=16, out_channels=16,\n",
        "        kernel_size=3, padding=1)\n",
        "        self.bn5 = nn.BatchNorm2d(num_features=16)\n",
        "        self.conv6 = nn.Conv2d(in_channels=16, out_channels=32,\n",
        "        kernel_size=3, padding=1)\n",
        "        self.bn6 = nn.BatchNorm2d(num_features=32)\n",
        "       # self.conv7 = nn.Conv2d(in_channels=32, out_channels=32,\n",
        "        #kernel_size=1, padding=1)\n",
        "        self.gpool = nn.AvgPool2d(kernel_size=9)\n",
        "\n",
        "        self.out1 = nn.Sequential(\n",
        "            nn.Linear(32, 10)\n",
        "        )\n",
        "        self.drop = nn.Dropout2d(0.1)\n",
        "    def forward(self, x):\n",
        "        x = self.tns1(self.drop(self.bn1(F.relu(self.conv1(x)))))\n",
        "        x = self.drop(self.bn2(F.relu(self.conv2(x))))\n",
        "        x = self.pool1(x)\n",
        "        x = self.drop(self.bn3(F.relu(self.conv3(x))))\n",
        "        x = self.drop(self.bn4(F.relu(self.conv4(x))))\n",
        "        x = self.tns2(self.pool2(x))\n",
        "        x = self.drop(self.bn5(F.relu(self.conv5(x))))\n",
        "        x = self.drop(self.bn6(F.relu(self.conv6(x))))\n",
        "        #print(x.shape)\n",
        "        #x = self.conv7(x)\n",
        "        #print(x.shape)\n",
        "        x = self.gpool(x)\n",
        "        x = x.view(-1, 32)\n",
        "        x = self.out1(x)\n",
        "        #print(x.shape)\n",
        "\n",
        "        return F.log_softmax(x)"
      ],
      "metadata": {
        "id": "8l0b0qTjN6sN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchsummary\n",
        "#API to view the visualization of the model, which is helpful while debugging your network.\n",
        "from torchsummary import summary\n",
        "# Returns a bool indicating if CUDA is currently available.\n",
        "# NVIDIAâ€™s CUDA is a general purpose parallel computing platform and programming model that accelerates deep learning and other compute-intensive apps by taking advantage of the parallel processing power of GPUs.\n",
        "use_cuda = torch.cuda.is_available()\n",
        "# A torch.device is an object representing the device on which a torch.Tensor is or will be allocated.\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "# Specify which device to use\n",
        "model = Net().to(device)\n",
        "# Model summary\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4E-VkHE4N_5X",
        "outputId": "ec50c414-9160-4497-8b99-377b50d3e94b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.8/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 128, 28, 28]           1,280\n",
            "       BatchNorm2d-2          [-1, 128, 28, 28]             256\n",
            "         Dropout2d-3          [-1, 128, 28, 28]               0\n",
            "            Conv2d-4            [-1, 8, 30, 30]           1,032\n",
            "            Conv2d-5           [-1, 16, 30, 30]           1,168\n",
            "       BatchNorm2d-6           [-1, 16, 30, 30]              32\n",
            "         Dropout2d-7           [-1, 16, 30, 30]               0\n",
            "         MaxPool2d-8           [-1, 16, 15, 15]               0\n",
            "            Conv2d-9           [-1, 16, 15, 15]           2,320\n",
            "      BatchNorm2d-10           [-1, 16, 15, 15]              32\n",
            "        Dropout2d-11           [-1, 16, 15, 15]               0\n",
            "           Conv2d-12           [-1, 32, 15, 15]           4,640\n",
            "      BatchNorm2d-13           [-1, 32, 15, 15]              64\n",
            "        Dropout2d-14           [-1, 32, 15, 15]               0\n",
            "        MaxPool2d-15             [-1, 32, 7, 7]               0\n",
            "           Conv2d-16             [-1, 16, 9, 9]             528\n",
            "           Conv2d-17             [-1, 16, 9, 9]           2,320\n",
            "      BatchNorm2d-18             [-1, 16, 9, 9]              32\n",
            "        Dropout2d-19             [-1, 16, 9, 9]               0\n",
            "           Conv2d-20             [-1, 32, 9, 9]           4,640\n",
            "      BatchNorm2d-21             [-1, 32, 9, 9]              64\n",
            "        Dropout2d-22             [-1, 32, 9, 9]               0\n",
            "        AvgPool2d-23             [-1, 32, 1, 1]               0\n",
            "           Linear-24                   [-1, 10]             330\n",
            "================================================================\n",
            "Total params: 18,738\n",
            "Trainable params: 18,738\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 3.07\n",
            "Params size (MB): 0.07\n",
            "Estimated Total Size (MB): 3.14\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-2e48604e0afa>:57: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "# model defined above\n",
        "# device in this case will cpu\n",
        "# train loader to download training images and transform into tensor \n",
        "# SGD optimizer\n",
        "# The learning rate controls how quickly the model is adapted to the problem. Smaller learning rates require more training epochs given the smaller changes made to the weights each update, whereas larger learning rates result in rapid changes and require fewer training epochs.\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad() # Sets the gradients of all optimized torch.Tensor s to zero.\n",
        "        output = model(data)\n",
        "        # loss function\n",
        "        loss = F.nll_loss(output, target) # loss function - The negative log likelihood loss.\n",
        "        loss.backward() \n",
        "        optimizer.step()\n",
        "        pbar.set_description(desc= f'loss={loss.item()} batch_id={batch_idx}')\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))"
      ],
      "metadata": {
        "id": "WVMf0lJsOQx3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Sets the seed for generating random numbers. Returns a torch.Generator object.\n",
        "\n",
        "torch.manual_seed(1)\n",
        "#batch_size = 128\n",
        "batch_size = 128\n",
        "#PyTorch's DataLoader class, which in addition to our Dataset class, also takes in the following important arguments:\n",
        "\n",
        "#batch_size, which denotes the number of samples contained in each generated batch.\n",
        "#shuffle. If set to True, we will get a new order of exploration at each pass (or just keep a linear exploration scheme otherwise). Shuffling the order in which examples are fed to the classifier is helpful so that batches between epochs do not look alike. Doing so will eventually make our model more robust.\n",
        "#num_workers, which denotes the number of processes that generate batches in parallel. A high enough number of workers assures that CPU computations are efficiently managed, i.e. that the bottleneck is indeed the neural network's forward and backward operations on the GPU (and not data generation).\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "# Download training data \n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True, \n",
        "                    transform=transforms.Compose([ # Composes several transforms together.\n",
        "                        transforms.ToTensor(), # Convert a PIL Image or numpy.ndarray to tensor.\n",
        "                        transforms.Normalize((0.1307,), (0.3081,)) # Normalize(mean, std[, inplace]) Normalize a tensor image with mean and standard deviation.\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ])),\n",
        "    batch_size=batch_size, shuffle=True, **kwargs)\n"
      ],
      "metadata": {
        "id": "GsvwkVJFOmJg"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "\n",
        "#torch.optim.SGD(params, lr=<required parameter>, momentum=0, dampening=0, weight_decay=0, nesterov=False, *, maximize=False, foreach=None, differentiable=False)\n",
        "#params (iterable) â€“ iterable of parameters to optimize or dicts defining parameter groups\n",
        "\n",
        "#lr (float) â€“ learning rate\n",
        "\n",
        "#momentum (float, optional) â€“ momentum factor (default: 0)\n",
        "\n",
        "#weight_decay (float, optional) â€“ weight decay (L2 penalty) (default: 0)\n",
        "\n",
        "#dampening (float, optional) â€“ dampening for momentum (default: 0)\n",
        "\n",
        "#nesterov (bool, optional) â€“ enables Nesterov momentum (default: False)\n",
        "\n",
        "#maximize (bool, optional) â€“ maximize the params based on the objective, instead of minimizing (default: False)\n",
        "\n",
        "#foreach (bool, optional) â€“ whether foreach implementation of optimizer is used (default: None)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
        "epochs = 20\n",
        "for epoch in range(1, epochs + 1):\n",
        "    print('epoch value is , ', epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)\n",
        "\n",
        "# Test set: Average loss: 0.3189, Accuracy: 8758/10000 (88%) - lr=0.01, momentum=0.9 , epoch 1, batch_size = 128\n",
        "# Test set: Average loss: 0.4987, Accuracy: 7927/10000 (79%) - lr=0.02, momentum=0.9 , epoch 1 , batch_size = 128\n",
        "# Test set: Average loss: 1.8482, Accuracy: 3000/10000 (30%) - lr=0.03, momentum=0.9 , epoch 1 , batch_size = 128\n",
        "# lr=0.01, momentum=0.9 , epoch 9\n",
        "# accuracy at epoch 3\n",
        "#Test set: Average loss: 0.0377, Accuracy: 9874/10000 (99%)\n",
        "\n",
        "# accuracy starts decreasing for same parameters even after run time restart\n",
        "#Test set: Average loss: 0.7211, Accuracy: 6943/10000 (69%) # lr=0.01, momentum=0.9 , epoch 4  , batch_size = 128\n",
        "\n",
        "### changing batch size to 16\n",
        "\n",
        "#Test set: Average loss: 1.4329, Accuracy: 4815/10000 (48%) # lr=0.01, momentum=0.9 , epoch 4  , batch_size = 16\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhRT73elO9r4",
        "outputId": "4a5846f1-db5b-4c16-8706-539da110ce61"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch value is ,  1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/469 [00:00<?, ?it/s]<ipython-input-30-2e48604e0afa>:57: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.log_softmax(x)\n",
            "loss=0.267739862203598 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:23<00:00, 20.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.1443, Accuracy: 9631/10000 (96%)\n",
            "\n",
            "epoch value is ,  2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.19418276846408844 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:19<00:00, 24.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0666, Accuracy: 9803/10000 (98%)\n",
            "\n",
            "epoch value is ,  3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.20069916546344757 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:19<00:00, 24.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0523, Accuracy: 9834/10000 (98%)\n",
            "\n",
            "epoch value is ,  4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.15424950420856476 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:19<00:00, 23.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0434, Accuracy: 9864/10000 (99%)\n",
            "\n",
            "epoch value is ,  5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.05928570404648781 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:19<00:00, 24.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0388, Accuracy: 9875/10000 (99%)\n",
            "\n",
            "epoch value is ,  6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.056334927678108215 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:19<00:00, 24.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0359, Accuracy: 9885/10000 (99%)\n",
            "\n",
            "epoch value is ,  7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.1815665364265442 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:20<00:00, 23.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0333, Accuracy: 9888/10000 (99%)\n",
            "\n",
            "epoch value is ,  8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.11918257921934128 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:19<00:00, 24.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0308, Accuracy: 9890/10000 (99%)\n",
            "\n",
            "epoch value is ,  9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.09962964057922363 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:19<00:00, 24.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0273, Accuracy: 9906/10000 (99%)\n",
            "\n",
            "epoch value is ,  10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.05883053317666054 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:19<00:00, 24.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0263, Accuracy: 9906/10000 (99%)\n",
            "\n",
            "epoch value is ,  11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.07924439758062363 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:19<00:00, 24.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0244, Accuracy: 9919/10000 (99%)\n",
            "\n",
            "epoch value is ,  12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.08207419514656067 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:19<00:00, 24.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0264, Accuracy: 9907/10000 (99%)\n",
            "\n",
            "epoch value is ,  13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.03615778312087059 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:19<00:00, 24.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0241, Accuracy: 9915/10000 (99%)\n",
            "\n",
            "epoch value is ,  14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.012351428158581257 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:19<00:00, 24.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0275, Accuracy: 9905/10000 (99%)\n",
            "\n",
            "epoch value is ,  15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.011305642314255238 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:20<00:00, 23.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0208, Accuracy: 9920/10000 (99%)\n",
            "\n",
            "epoch value is ,  16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.08492306619882584 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:19<00:00, 24.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0197, Accuracy: 9933/10000 (99%)\n",
            "\n",
            "epoch value is ,  17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.05725876986980438 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:19<00:00, 24.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0191, Accuracy: 9948/10000 (99%)\n",
            "\n",
            "epoch value is ,  18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.08754882216453552 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:19<00:00, 23.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0203, Accuracy: 9922/10000 (99%)\n",
            "\n",
            "epoch value is ,  19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.03545418009161949 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:19<00:00, 23.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0203, Accuracy: 9932/10000 (99%)\n",
            "\n",
            "epoch value is ,  20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loss=0.024912239983677864 batch_id=468: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 469/469 [00:19<00:00, 23.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test set: Average loss: 0.0192, Accuracy: 9942/10000 (99%)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}